{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!flask/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# for mysql & mongo\n",
    "#import mysql.connector\n",
    "#from mysql.connector import errorcode\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# for api\n",
    "from flask import Flask, jsonify, abort, make_response, request, render_template, Markup\n",
    "from flask_cors import CORS\n",
    "import json\n",
    "import collections\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import urllib\n",
    "\n",
    "# for country_info_templates\n",
    "#import templates\n",
    "\n",
    "\n",
    "app = Flask(__name__, template_folder='templates')\n",
    "\n",
    "# for CORS\n",
    "cors = CORS(app, resources={r\"/api/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return \"Hello, world! This is for August POC\"\n",
    "\n",
    "@app.route('/api/test/', methods=['GET'])\n",
    "def get_test():\n",
    "\tname = request.args.get('name', '', type=str); #type=str要去除掉，否則會有編碼問題\n",
    "\tprint name;\n",
    "\treturn name;\n",
    "\n",
    "# potential projects\n",
    "@app.route('/api/landing-map-markers/landing-map-markers/potential-projects/', methods=['GET'])\n",
    "def get_potential_projects():\n",
    "    # connect to mysql\n",
    "    cnx = mysql.connector.connect(user='root', password='obor3',\n",
    "                              host='obor-mysql',\n",
    "                              database='tpdb',\n",
    "                              charset='utf8')\n",
    "    cursor = cnx.cursor()\n",
    "    res = list()\n",
    "\n",
    "    # get the parameter from args\n",
    "    country_id = request.args.get('country_id', '', type=str).replace('\"','').replace(\"'\",\"\")\n",
    "\n",
    "    # sql script\n",
    "    query_all = \"SELECT tender_no, description, category, institute, location, country_id, longitude, latitude, advertised_date, closing_date, related_link FROM POTENTIALITEM;\"\n",
    "    #query2 = 'select tender_no, description, category, institute, location, country_id, longitude, latitude, advertised_date, closing_date, related_link FROM POTENTIALITEM where country_id =  %s;' % (country_id)\n",
    "    query_country = \"SELECT tender_no, description, category, institute, location, country_id, longitude, latitude, advertised_date, closing_date, related_link FROM POTENTIALITEM where country_id ='{0}';\".format(country_id)\n",
    "    \n",
    "    # check the country_id value and then query the data\n",
    "    if country_id:\n",
    "        cursor.execute(query_country)\n",
    "        alldata = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        if alldata:\n",
    "            return jsonify(alldata) \n",
    "        else:\n",
    "            return jsonify({'error': 'County Not found'})\n",
    "    else:\n",
    "        cursor.execute(query_all)\n",
    "        alldata = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return jsonify(alldata)\n",
    "\n",
    "# potential projects\n",
    "@app.route('/api/potential_item/', methods=['GET'])\n",
    "def get_potential_items():\n",
    "    # connection's parameter\n",
    "    config = {\n",
    "        'host': 'obor-mysql',\n",
    "        'user': 'root', \n",
    "        'password': 'obor3',\n",
    "        'charset': 'utf8'\n",
    "    }\n",
    "\n",
    "    # connect db\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**config)\n",
    "    except mysql.connector.Error as e:\n",
    "        return jsonify({'error': 'Connect failed! -- ' + str(e)})\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # get the parameter from args\n",
    "    country_id = request.args.get('country_id', '', type=str).replace('\"','').replace(\"'\",\"\")\n",
    "\n",
    "    # use request.args.get() got empty for chinese\n",
    "    if 'industry_id' in request.args:\n",
    "        industry_id = request.args['industry_id'].replace('\"','').replace(\"'\",\"\").encode('utf8')\n",
    "\n",
    "        # if industry_id == industry code, use mapping table\n",
    "        industry_table = {\n",
    "            \"0\": \"制造业\",\n",
    "            \"1\": \"交通运输\",\n",
    "            \"10\": \"水利环境和公共\",\n",
    "            \"11\": \"建筑业\",\n",
    "            \"12\": \"批发和零售业\",\n",
    "            \"13\": \"军事\",\n",
    "            \"14\": \"卫生\",\n",
    "            \"2\": \"金融\",\n",
    "            \"3\": \"房地产\",\n",
    "            \"4\": \"餐饮和住宿\",\n",
    "            \"5\": \"居民服务\",\n",
    "            \"6\": \"教育\",\n",
    "            \"7\": \"文体\",\n",
    "            \"8\": \"农林牧渔业\",\n",
    "            \"9\": \"电力热力燃气\",\n",
    "            \"999\": \"其他\"\n",
    "        }\n",
    "        if industry_id.isdigit():\n",
    "            if industry_id in industry_table:\n",
    "                industry_id = industry_table[industry_id]\n",
    "            else:\n",
    "                return jsonify({\"result\": \"industry code not founded\"})\n",
    "\n",
    "        # use two words for fuzzy query\n",
    "        industry_id = unicode(industry_id.decode('utf-8'))[:2].encode('utf8') if len(unicode(industry_id.decode('utf-8'))) > 2 else industry_id\n",
    "        \n",
    "        # for 農林牧漁業\n",
    "        if industry_id == '农林':\n",
    "            industry_id = '农、'\n",
    "    else:\n",
    "        industry_id = ''\n",
    "\n",
    "    # create query script\n",
    "    query_filter = ''\n",
    "    if country_id and industry_id:\n",
    "        query_filter = \"WHERE country.ID='{0}' AND pot.industry LIKE '%{1}%'\".format(country_id, str(industry_id))\n",
    "    else:\n",
    "        if country_id:\n",
    "            query_filter = \"WHERE country.ID= '{0}'\".format(country_id)\n",
    "        if industry_id:\n",
    "            query_filter = \"WHERE pot.industry LIKE '%{0}%'\".format(str(industry_id))\n",
    "        \n",
    "    query_script = \"\"\"\n",
    "        SELECT pot.item_name, pot.release_date, pot.item_type, pot.invest_type, pot.industry, pot.location, \\\n",
    "        pot.duration, pot.amount, pot.attract_investment_amount, pot.mark, pot.description, pot.person_name, \\\n",
    "        pot.organization, pot.position, pot.phone, pot.email, country.LATITUDE, country.LONGITUDE \\\n",
    "        FROM tpdb.POTENTIALITEMNEW AS pot \\\n",
    "        LEFT JOIN ciip.COUNTRY AS country \\\n",
    "        ON pot.location = country.NAME \\\n",
    "        %s \\\n",
    "        ORDER BY pot.release_date DESC \\\n",
    "    \"\"\" % (query_filter) \n",
    "            \n",
    "    # return default change to dictionary\n",
    "    cur = cnx.cursor(buffered=True, dictionary=True)\n",
    "\n",
    "    # query from db\n",
    "    cur.execute(query_script)\n",
    "    res = cur.fetchall()\n",
    "    cur.close()\n",
    "    cnx.close()\n",
    "    if res:\n",
    "        return jsonify(res)\n",
    "    else:\n",
    "        return jsonify({\"result\": \"NO DATA\"})\n",
    "\n",
    "\n",
    "# country info\n",
    "@app.route('/api/country_info/<country>/<industry>')\n",
    "def get_country_info(country, industry):\n",
    "    # connect to mongodb and query data\n",
    "    client = MongoClient('obor-mongo', 27017)\n",
    "    data = client['obor']['obor_countryInfo'].find_one({\"country_code\": country})\n",
    "\n",
    "\n",
    "    # check country exist\n",
    "    if data is None:\n",
    "        return jsonify({'error': 'County Not Found'})\n",
    "\n",
    "    # check industry exist\n",
    "    if industry not in data:\n",
    "        return jsonify({'error': 'Industry Not Found'})\n",
    "\n",
    "    # for disease\n",
    "    def article_title_counts(keyword, location, limit_months=2):\n",
    "        '''Return counts from articles which contain the keyword'''\n",
    "        two_month_ago = (datetime.datetime.now()-relativedelta(months=limit_months)).strftime(\"%Y-%m-%d\")\n",
    "        count = client['obor']['obor_article'].count({\n",
    "            \"$and\":[\n",
    "                {\n",
    "                    # filter title keywords\n",
    "                    \"_source.atitle\": {\n",
    "                        \"$regex\": \".*%s.*\" % keyword, \n",
    "                        \"$options\": \"-i\"  # ignore case\n",
    "                    }\n",
    "                },\n",
    "                \n",
    "                {\n",
    "                    # filter datetime\n",
    "                    \"_source.dateTime\": {\"$gt\": \"%s\" % two_month_ago}\n",
    "                },\n",
    "                {\n",
    "                    # filter country\n",
    "                    \"$or\": [\n",
    "                        {\n",
    "                            \"_source.location.country.wikiUri\": {\n",
    "                                \"$regex\": \".*%s.*\" % location, \n",
    "                                \"$options\": \"-i\"  # ignore case\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"_source.location.wikiUri\": {\n",
    "                                \"$regex\": \".*%s.*\" % location, \n",
    "                                \"$options\": \"-i\"  # ignore case\n",
    "                            }\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "        return count\n",
    "    # only society contain a dynamic infomation (disease)\n",
    "    if  industry == \"society\":\n",
    "        keywords = {\n",
    "            \"epidemic\": u\"疫情\", \n",
    "            \"diarrhea\": u\"腹泻\", \n",
    "            \"infectious\": u\"感染​​性疾病\",\n",
    "            \"Hepatitis\": u\"肝炎\",\n",
    "            \"Typhoid\": u\"伤寒\", \n",
    "            \"dengue\": u\"登革热\",\n",
    "            \"malaria\": u\"疟疾\", \n",
    "            \"rabies\": u\"狂犬病\",\n",
    "            \"poliomyelitis\": u\"脊髓灰质炎\"\n",
    "        }\n",
    "        disease_res = list()\n",
    "\n",
    "        # if counts > 0, we claim the disease existed\n",
    "        for k, v in keywords.items():\n",
    "            counts = article_title_counts(k, \"pakistan\")\n",
    "            if counts:\n",
    "                disease_res.append(v)\n",
    "        data['society']['major_infectious_diseases_current'] = unicode(', '.join(disease_res))\n",
    "\n",
    "    # map key with zh-simple\n",
    "    with open(\"data/label_map.json\", \"r\") as f:\n",
    "        label_title = json.loads(f.read())\n",
    "\n",
    "    # order the data for html layout\n",
    "    ord_data = collections.OrderedDict(sorted(data[industry].items()))\n",
    "    client.close()\n",
    "    return render_template('countryInfo.html', data=ord_data, label = label_title)\n",
    "\n",
    "# countryback info\n",
    "@app.route('/api/countryback_info/<country>')\n",
    "def get_countryback_info(country):\n",
    "    # connection's parameter\n",
    "    config = {\n",
    "        'host': 'obor-mysql',\n",
    "        'user': 'root', \n",
    "        'password': 'obor3',\n",
    "        'database': 'tpdb',\n",
    "        'charset': 'utf8'\n",
    "    }\n",
    "\n",
    "    # connect db\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(**config)\n",
    "    except mysql.connector.Error as e:\n",
    "        return jsonify({'error': 'Connect failed! -- ' + str(e)})\n",
    "    else:\n",
    "        pass\n",
    "    # return default change to dictionary\n",
    "    cur = cnx.cursor(buffered=True, dictionary=True)\n",
    "    # query from db\n",
    "    cur.execute('SELECT * FROM COUNTRYBACK WHERE country_id = \"%s\";'% country)\n",
    "    res = cur.fetchall()\n",
    "    cur.close()\n",
    "    cnx.close()\n",
    "\n",
    "    # CHECK query data exist\n",
    "    if res:\n",
    "        return Markup(res[0]['background'])\n",
    "    else:\n",
    "        return jsonify({'error': 'Country Not Found'}) \n",
    "\n",
    "\n",
    "@app.errorhandler(404)\n",
    "def not_found(error):\n",
    "    '''Handle error code'''\n",
    "    return make_response(jsonify({'error': 'Not Found'}), 404)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # app.debug=True\n",
    "    app.run(host=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哈哈\r\n",
      "\t\t\t\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from flask import Flask, jsonify, abort, make_response, request, render_template, Markup\n",
    "from flask_cors import CORS\n",
    "import json\n",
    "\n",
    "app = Flask(__name__, template_folder='templates')\n",
    "\n",
    "\n",
    "    \n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    #return \"Hello, world! This is for August PO5\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/api/test/', methods=['POST','GET'])\n",
    "def get_test():\n",
    "    content = request.form.get('content', '預設值')\n",
    "    #content = request.args.get('content', '') #type=str要去除掉，否則會有編碼問題\n",
    "    print content;\n",
    "    return content;\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # app.debug=True\n",
    "    app.run(host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mongodb 連線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\TextMining\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\ytchen\\appdata\\local\\temp\\jieba.ufb55ea6623e696143f43e248198acd74.cache\n",
      "Loading model cost 1.355 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pymongo import MongoClient \n",
    "\n",
    "#預設就是自己\n",
    "client = MongoClient('127.0.0.1', 27017)\n",
    "database = client['test']\n",
    "collection =database['news']\n",
    "client.close()\n",
    "\n",
    "import jieba\n",
    "jieba.set_dictionary('D:/TextMining/dict.txt.big.txt')  #切換至中文繁體字庫\n",
    "jieba.load_userdict(\"D:/TextMining/dict_keyw.txt\")       #加入自建詞庫\n",
    "jieba.load_userdict(\"D:/TextMining/ptt.txt\")       #加入PTT詞庫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓取資料，製作模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "超級7歲娃扛家顧盲母3弟妹-煮飯-洗衣-換燈管\n",
      "文章數:200\n"
     ]
    }
   ],
   "source": [
    "#給關鍵字----------------------------------------\n",
    "tag1 = \"我\"\n",
    "# tag2 = \"台灣\"\n",
    "#-----------------------------------------------\n",
    "\n",
    "date=[]\n",
    "title=[]\n",
    "content =[]\n",
    "all_article = []\n",
    "#把資料庫東西抓出來\n",
    "for post in collection.find(\n",
    "    {\"$and\":[                   \n",
    "            {\"content\":{\"$regex\":tag1}},\n",
    "#             {\"content\":{\"$regex\":tag2}},\n",
    "            #{\"date\":{\"$regex\":\"2016\"}},\n",
    "            ]},{\"_id\":0}).limit(200): \n",
    "    summary = post['content']\n",
    "    all_article.append(summary)\n",
    "    content.append(' '.join(jieba.cut(summary)))\n",
    "    title.append(post['title'])\n",
    "    date.append(post['date'])\n",
    "    \n",
    "client.close()\n",
    "\n",
    "print title[0]\n",
    "\n",
    "#文章數\n",
    "newsNumber = len(title)\n",
    "print \"文章數:\" + str(newsNumber)\n",
    "\n",
    "# 將使用者輸入文章，塞入第一篇內容\n",
    "mysummary = '''大陸著名民俗專家王作楫在一段影片中指出，人們把「福」字倒貼是「絶對原則性的錯誤」，雖然傳統文化中的確有倒貼福字的地方，但是是在垃圾桶、水桶等器具上。「福字為什麼不能倒貼」話題成了昨天微博熱搜首位，兩派人馬就此展開了激烈討論。\n",
    "北京青年報報導，對於「福」字不應倒貼的問題，其實王作楫以前就多次講過，他的理由主要有三個。\n",
    "其一，「福」是中國人的文化符號，中國有兩個傳統文化符號，一個是「圓」一個是「方」，就是古話講「天圓地方」。「圓」有圓圓滿滿、團團圓圓的含義；「方」的含義更重要，因為中國文字是方塊字，我們用方塊字記載了中國五千年的文明史，所以倒貼「福」字等於是把中國的傳統文化符號倒過來使用，「這不是顛倒黑白嗎，這是對文字和中國文化的不尊重」。\n",
    "其二，「福」字除了部首「示字部」，右邊則由「一、口、田」三個字組成。按照古代說文解字的說法，「一」代表房子的房梁，「口」是房子裏邊住著的人口，「如果把它倒過來，你這房子和人口不就等於跑到田地下面去了嗎，你想想那是什麼」。\n",
    "其三，大家認為把福倒過來貼就意味著「福到了」，他說，這是一種誤解。因為倒貼的這個倒是「倒掉」的意思，不是「來到」的「到」，兩者是有區別的。\n",
    "王作楫進一步指出，傳統文化中的確有倒貼福字的地方，但是是在垃圾桶、水桶等器具上。\n",
    "因為垃圾代表著災害和貧窮，所以需要倒掉，過去人們把倒垃圾稱為「扔災」。而福字倒貼在垃圾桶上，當倒掉垃圾時，垃圾桶底朝天，倒貼的福字就變正了，意思是把災和貧窮扔掉，福才會來。'''\n",
    "all_article.insert(0, summary)\n",
    "content.insert(0, ' '.join(jieba.cut(summary)))\n",
    "title.insert(0, 'fortest')\n",
    "date.insert(0,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fortest\n"
     ]
    }
   ],
   "source": [
    "print title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-IDF 權重計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徵值數量: 14583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(content)  # titile 放文本\n",
    "weight = X.toarray() #裝關鍵字的權重值\n",
    "\n",
    "#特徵值總共有多少個\n",
    "features = vectorizer.get_feature_names()     # 拿到所有的關鍵詞  \n",
    "print \"特徵值數量:\",len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拿到每篇文章的TOP TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "執行時間: 4.22381045705 秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "\n",
    "top_features = []\n",
    "final_top_features = []\n",
    "for n in range(0,newsNumber):  #迴圈參考上面的總文章數\n",
    "    #裝每天文章的feature & score\n",
    "    map_top_features = []\n",
    "    \n",
    "    #對特徵詞的index進行排序\n",
    "    indices = np.argsort(weight[n])[::-1] #weight[n] 是第幾篇新聞的意思\n",
    "    \n",
    "    #拿到所有的特徵詞\n",
    "    features = vectorizer.get_feature_names()\n",
    "    \n",
    "    #截取TOP多少的詞\n",
    "    top_n = 40\n",
    "    \n",
    "    ###################################把每篇的TOP TF-IDF 與其分數存起來###############################################\n",
    "    #將每天文章的TOP-TFIDF存起來\n",
    "    top_features.append([features[i] for i in indices[:top_n]])\n",
    "    \n",
    "    a=0\n",
    "    for i in top_features[n]:\n",
    "#         print i,weight[n][indices[a]]\n",
    "        data = {\n",
    "            'feature':i,\n",
    "            'score':weight[n][indices[a]]\n",
    "        }\n",
    "        #print data['score'],data['feature']\n",
    "        a=a+1\n",
    "        \n",
    "        map_top_features.append(data)\n",
    "    final_top_features.append(map_top_features)\n",
    "# print final_top_features[0]\n",
    "    #############################################################################################\n",
    "    \n",
    "toc = time.clock()\n",
    "print \"執行時間:\",(toc - tic),\"秒\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文章摘要運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均分數=0.428970476272\n",
      "---------------------------------------------\n",
      "新聞標題：fortest\n",
      "------------\n",
      "文章摘要：\n",
      "【鮮明、高堂堯╱連線報導】成立三十一年玉管處開出首張違規露營罰單！玉山國家公園管理處與警方前天在塔塔加遊客中心停車場取締違規露營族，依《國家公園法》開罰一千五百元罰鍰；玉管處表示，前天開出的罰單為成立以來第一張違規露營告發單，今年對違規露營民眾已開出五十八張勸導單，前天約七至八成停車格遭露營族霸佔，三人回嗆：「不管啦！我們就是要在這邊過夜！」警員依《國家公園法》開出一千五百元罰單，首張違規露營罰單」，明訂未經核准禁止在停車場及指定以外之地區露營、野炊、炊事、燃火、搭設帳篷、放置桌椅、大聲喧鬧及舉行營火等活動，一般違規露營民眾遇警方或管理處人員勸導，停車場一向是露營熱門地點，遊客中心停車場擠滿露營民眾，禁止民眾以露營車露營野炊，進行露營野炊等主管機關禁止行為，第二次以上違規處3000元罰鍰★生火需在合法地點。\n",
      "------------\n",
      "文章原文：\n",
      "【鮮明、高堂堯╱連線報導】成立三十一年玉管處開出首張違規露營罰單！玉山國家公園管理處與警方前天在塔塔加遊客中心停車場取締違規露營族，三名二十多歲年輕人佔據停車格紮營，玉管處及警方廣播、口頭三度勸離無效，依《國家公園法》開罰一千五百元罰鍰；玉管處表示，前天開出的罰單為成立以來第一張違規露營告發單，今年對違規露營民眾已開出五十八張勸導單。玉山國家公園管理處副處長林文和表示，塔塔加遊客中心周邊停車場約四十個停車格，前天約七至八成停車格遭露營族霸佔，除拿出炊具煮食還著手紮營。其中來自彰化的周姓等三名年約二十三至二十四歲年輕男子，騎機車載蒙古包等露營器具搭設，警方先廣播驅離，下午五時二度口頭勸離，未料三人晚間八時許仍在原地，警員三度要求離開，三人回嗆：「不管啦！我們就是要在這邊過夜！」警員依《國家公園法》開出一千五百元罰單，林文和指「這是玉管處成立三十一年來，首張違規露營罰單」。林文和強調，玉管處有鑑於長期勸導未見具體成效，前年修訂玉山國家公園區域內公告禁止事項，明訂未經核准禁止在停車場及指定以外之地區露營、野炊、炊事、燃火、搭設帳篷、放置桌椅、大聲喧鬧及舉行營火等活動，第一次違規罰一千五百元罰鍰，第二次以上違規罰三千元罰鍰。內政部營建署國家公園組組長詹德樞表示，一般違規露營民眾遇警方或管理處人員勸導，通常都會收起帳篷；前天不服勸說取締的情況，較為罕見。常露營的簡姓男子說，塔塔加環境清幽，還有廁所可供水，加上晚上可觀星，停車場一向是露營熱門地點，但現開出第一張罰單，「恐怕有一段時間不能再去露營了！」另有洪姓民眾向《蘋果》投訴，指前天到塔塔加遊玩，下午三時許，遊客中心停車場擠滿露營民眾，其他人無處可停，他聽到清潔工抱怨，露營遊客將菜渣倒廁所洗手台，導致排水管阻塞，「實在很沒公德心！」玉管處企劃課長黃俊銘表示，該處規劃五處簡易炊煮地點，分別在塔塔加台十八線一○九點一Ｋ、台十八線一○八點二Ｋ、台十八線一○八點一Ｋ、台二十一線一三二Ｋ（觀山）及梅山地區台二十線一二九Ｋ（中之關），可以沸水煮泡麵、泡茶或泡咖啡等，禁止使用大型爐具或炭火煮食烤肉；民眾若佔用停車格野炊或搭帳篷，因影響其他遊客權益，都列入管制。 另外，詹德樞提醒，國家公園停車場面積普遍不大，且未規劃專為露營車排放污水的管線，禁止民眾以露營車露營野炊。★尋找合法且安全地點紮營，避開落石及河水易暴漲區★違反《國家公園法》第13條第8項，進行露營野炊等主管機關禁止行為，首次違規處1500元罰鍰，第二次以上違規處3000元罰鍰★生火需在合法地點，若不慎失火先以砂土滅火資料來源：小路露營區負責人呂崇榮、谷關瓦浪露營區負責人羅金國\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#對所有的新聞文章進行 \"句子切詞 \"\n",
    "import re\n",
    "for article_index in range(0,1):\n",
    "    article = all_article[article_index] #一篇文章\n",
    "    setenceList = re.split(\"，|。|\",article.encode('utf-8')) #根據\"逗號\" & \"句號\" 進行句子斷開\n",
    "    \n",
    "    #裝一篇文章的句子 & 句子的分數\n",
    "    sen_score_map = []\n",
    "    article_score = 0 #文章的總分數\n",
    "    avg_score = 0 #總文章的平均分數\n",
    "    \n",
    "    #將每篇文章的句子逐一取出進行分數計算\n",
    "    for sen in setenceList:\n",
    "        #初始化句子分數\n",
    "        score = 0 \n",
    "        \n",
    "        #逐一抓出各文章的 map_top_features 特徵詞與分數，與句子進行比對，若該特徵詞存在於句子中，則分數加上去\n",
    "        for i in final_top_features[article_index]:\n",
    "            feature = i['feature'].encode('utf-8')\n",
    "            if feature in sen:\n",
    "                score += i['score']\n",
    "        \n",
    "        #存取句子與分數\n",
    "        data = {\n",
    "            'sentence' : sen,\n",
    "            'score' : score,\n",
    "        }\n",
    "        sen_score_map.append(data)\n",
    "        \n",
    "        #文章總分數\n",
    "        article_score += score\n",
    "        \n",
    "    #文章資訊\n",
    "    article_sen_size = len(setenceList) #文章句子總數\n",
    "    avg_score = article_score / article_sen_size #平均句子分數\n",
    "    \n",
    "    #文章摘要\n",
    "    articleSummarize = ''\n",
    "    skip = 0\n",
    "    for i in sen_score_map:\n",
    "        #第一句一定要有，加完就continue換下一個迴圈，不用跑下面的判斷\n",
    "        if skip == 0:\n",
    "            skip+=1\n",
    "            articleSummarize += '，'+i['sentence']\n",
    "            continue\n",
    "        #進行判斷(句子分數 > 平均分數才加入摘要)\n",
    "        if i['score'] > avg_score*1.5:\n",
    "            articleSummarize += '，'+i['sentence']\n",
    "    #修整文章摘要-最後面的逗號改成句號\n",
    "    articleSummarize = articleSummarize.replace('，','',1)+\"。\" #把最前面的逗號替換掉\n",
    "            \n",
    "    print '平均分數=' + str(avg_score)\n",
    "    print '---------------------------------------------'\n",
    "    print '新聞標題：'+title[article_index].encode('utf-8')\n",
    "    print '------------'\n",
    "    print '文章摘要：'\n",
    "    print articleSummarize\n",
    "    print '------------'\n",
    "    print '文章原文：'\n",
    "    print article\n",
    "    print '---------------------------------------------'    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
